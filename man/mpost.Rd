% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MPost.R
\name{mpost}
\alias{mpost}
\title{M-Posterior Algorithm for Parameter Estimation}
\usage{
mpost(
  chains,
  para,
  startval,
  niter,
  X,
  prior,
  likelihood,
  propvar = NULL,
  burn.rate = 0.1,
  random = T
)
}
\arguments{
\item{chains}{Number of subsets in the simulation. Used when a divide-and-conquer algorithm is employed.}

\item{para}{Parameters to be estimated.}

\item{startval}{Initial value of the chain.}

\item{niter}{Number of iterations (including burned iterations).}

\item{X}{Matrix of observations from the underlying data set.}

\item{prior}{Prior function for the parameters.}

\item{likelihood}{Likelihood function.}

\item{propvar}{The diagonal of the variance matrix for the proposal distribution. If no value is specified, the identify matrix is used.}

\item{burn.rate}{The percentage of iterations to be burned.}

\item{random}{If true, the rows of X are shuffled prior to the split.}
}
\value{
A list with the following items:
\describe{
\item{\code{Chains}}{A list of dataframes, one for each subset, containing the generated Markov chains.}
\item{\code{Estimate}}{The parameter estimate obtained using the M-posterior method.}
}
}
\description{
This function estimates the parameters of a model using the M-posterior method developped by Minsker et al. (2014). It models the subposterior of subset \eqn{X_k} as
\deqn{\pi_k(\theta | X_k) ∝ \pi(\theta) (\prod p(x|\theta))^K}
Parameter estimates are subsequently weighted according to their geometric mean.
}
\examples{
#Parameter estimation for data from a Weibull distribution

#Prior
prior<-function(param){
  ifelse(all(param>0), 1, 0)
}

#Likelihood
weibull.likelihood<-function(X, param){
  shape=param[1]
  scale=param[2]
  sum(dweibull(x=X, shape, scale, log=TRUE))
}

#Simulate data
X<-rweibull(100, 2, 1.2)

#Parameters
chains<-10
para<-c("shape", "scale")
niter<-10000
startval<-c(1.5, 1)
likelihood=weibull.likelihood

df<-mpost(chains, para, startval, niter, X, prior, likelihood,
          propvar=NULL, burn.rate=0.1, random=TRUE)
}
\references{
Stanislav Minsker, Sanvesh Srivastava, Lizhen Lin, and David B. Dunson. Scalable and robust bayesian inference via the median posterior. In Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32, ICML’14, page II–1656–II–1664. JMLR.org, 2014.
}
